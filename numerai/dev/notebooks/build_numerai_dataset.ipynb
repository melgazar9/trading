{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook builds the stock market / numerai dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "breeding-triumph"
   },
   "source": [
    "### Imports\n",
    "All other necessary imports are imported via python scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "amber-cabin"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make cells wider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU-UGOk2rA8w"
   },
   "source": [
    "### Only run the below if on google colab notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vQqHDb0qRLd",
    "outputId": "6731e0c2-99ac-40b0-b86c-5ecf33dbb34f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UreNrl9srNXa"
   },
   "outputs": [],
   "source": [
    "# sys.path.append('/content/gdrive/trading/dev/scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0l6obyRwr9qy"
   },
   "outputs": [],
   "source": [
    "# from gdrive.MyDrive.trading.dev.scripts.ML_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBnjdmz6rOHn"
   },
   "source": [
    "### Only run if on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "continuous-chemical"
   },
   "outputs": [],
   "source": [
    "os.chdir('../..') # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "chief-death"
   },
   "outputs": [],
   "source": [
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.7 s, sys: 1.99 s, total: 3.7 s\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dev.scripts.ML_utils import * # run if on local machine\n",
    "from dev.scripts.numerai_utils import *\n",
    "\n",
    "from dev.scripts.trading_utils import * # run if on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "norwegian-insured"
   },
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the numerai keys via config parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('numerai/numerai_keys.ini')\n",
    "\n",
    "OUTPUT_PATH = '/media/melgazar9/HDD_10TB/trading/data/yfinance/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "logical-stage"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99 µs, sys: 98 µs, total: 197 µs\n",
      "Wall time: 203 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DOWNLOAD_NUMERAI_COMPETITION_DATA = False\n",
    "LOAD_NUMERAI_COMPETITION_DATA = False\n",
    "\n",
    "DF_NUMERAI_COMP_TRAIN_PATH = '/media/melgazar9/HDD_10TB/trading/data/numerai_dataset_255/numerai_training_data.csv' # local\n",
    "\n",
    "napi = numerapi.SignalsAPI(config['KEYS']['NUMERAI_PUBLIC_KEY'], config['KEYS']['NUMERAI_SECRET_KEY'])\n",
    "\n",
    "# download data\n",
    "if DOWNLOAD_NUMERAI_COMPETITION_DATA:\n",
    "\n",
    "    # napi = numerapi.NumerAPI(NUMERAI_PUBLIC_KEY, NUMERAI_SECRET_KEY)\n",
    "    napi.download_current_dataset(unzip=True)\n",
    "\n",
    "if LOAD_NUMERAI_COMPETITION_DATA:\n",
    "    df_numerai_comp = dd.read_csv(DF_NUMERAI_COMP_TRAIN_PATH).compute()\n",
    "    display(df_numerai_comp.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZC3OYstYxhEB"
   },
   "source": [
    "## Load eligible tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jw1AlEWtxT6w",
    "outputId": "4ba6e5c5-67d3-4db5-d090-e4baf38373ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of eligible tickers: 5430\n",
      "Number of eligible tickers in map: 5430\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "      <th>yahoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>ZYXI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>ZZZ.</td>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker bloomberg_ticker   yahoo\n",
       "5428   ZYXI          ZYXI US    ZYXI\n",
       "5429   ZZZ.           ZZZ CN  ZZZ.TO"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eligible_tickers = pd.Series(napi.ticker_universe(), name='ticker')\n",
    "print(f\"Number of eligible tickers: {len(eligible_tickers)}\")\n",
    "ticker_map = pd.read_csv('https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_ticker_map_w_bbg.csv')\n",
    "ticker_map = ticker_map[ticker_map['bloomberg_ticker'].isin(eligible_tickers)]\n",
    "print(f\"Number of eligible tickers in map: {len(ticker_map)}\")\n",
    "ticker_map.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove null tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers before: (5430, 3)\n",
      "tickers after: (5380, 3)\n"
     ]
    }
   ],
   "source": [
    "valid_tickers = [i for i in ticker_map['yahoo']\n",
    "     if not pd.isnull(i)\n",
    "     and not str(i).lower()=='nan' \\\n",
    "     and not str(i).lower()=='null' \\\n",
    "     and not str(i).lower()==''\\\n",
    "]\n",
    "\n",
    "print('tickers before:', ticker_map.shape) # before removing bad tickers\n",
    "ticker_map = ticker_map[ticker_map['yahoo'].isin(valid_tickers)]\n",
    "print('tickers after:', ticker_map.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download or load in yahoo finance data in the expected numerai format using the yfinance library\n",
    "Yahoo Finance wrappers: https://github.com/ranaroussi/yfinance and https://pypi.org/project/yfinance/. <br>\n",
    "Downloading ~2 hours on a single-thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 s, sys: 33.6 s, total: 52 s\n",
      "Wall time: 31.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_1h_15</th>\n",
       "      <th>volume_1h_16</th>\n",
       "      <th>volume_1h_17</th>\n",
       "      <th>volume_1h_18</th>\n",
       "      <th>volume_1h_19</th>\n",
       "      <th>volume_1h_20</th>\n",
       "      <th>volume_1h_21</th>\n",
       "      <th>volume_1h_22</th>\n",
       "      <th>volume_1h_23</th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17616895</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>31.98</td>\n",
       "      <td>1.107286e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>4128.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>6188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17616896</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>31.879999</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>31.629999</td>\n",
       "      <td>31.98</td>\n",
       "      <td>1.107286e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>4128.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>6188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date yahoo_ticker  adj_close_1d   close_1d    high_1d  \\\n",
       "17616895 2021-04-06       ZZZ.TO     31.879999  31.879999  32.240002   \n",
       "17616896 2021-04-06       ZZZ.TO     31.879999  31.879999  32.240002   \n",
       "\n",
       "             low_1d  open_1d     volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "17616895  31.629999    31.98  1.107286e+09             NaN             NaN   \n",
       "17616896  31.629999    31.98  1.107286e+09             NaN             NaN   \n",
       "\n",
       "          ...  volume_1h_15  volume_1h_16  volume_1h_17  volume_1h_18  \\\n",
       "17616895  ...        6800.0        3943.0        4128.0        6819.0   \n",
       "17616896  ...        6800.0        3943.0        4128.0        6819.0   \n",
       "\n",
       "          volume_1h_19  volume_1h_20  volume_1h_21  volume_1h_22  \\\n",
       "17616895        6188.0           NaN           NaN           NaN   \n",
       "17616896        6188.0           NaN           NaN           NaN   \n",
       "\n",
       "          volume_1h_23  bloomberg_ticker  \n",
       "17616895           NaN            ZZZ CN  \n",
       "17616896           NaN            ZZZ CN  \n",
       "\n",
       "[2 rows x 153 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "DOWNLOAD_YAHOO_DATA = False\n",
    "if DOWNLOAD_YAHOO_DATA:\n",
    "    df_yahoo = dd.from_pandas(download_yfinance_data(list(ticker_map['yahoo']), start='2006-01-01')) # all valid yahoo tickers\n",
    "else:\n",
    "    DF_YAHOO_FILEPATH = '/media/melgazar9/HDD_10TB/trading/data/yfinance/df_yahoo_2021-04-07.pq'\n",
    "    NPARTITIONS=16\n",
    "    if DF_YAHOO_FILEPATH.lower().endswith('pq') or DF_YAHOO_FILEPATH.lower().endswith('parquet'):\n",
    "        df_yahoo = dd.read_parquet(DF_YAHOO_FILEPATH,\n",
    "                                    npartitions=NPARTITIONS).compute()\n",
    "    elif DF_YAHOO_FILEPATH.lower().endswith('feather'):\n",
    "        df_yahoo = dd.from_pandas(delayed(feather.read_dataframe)(DF_YAHOO_FILEPATH).compute(),\n",
    "                                   npartitions=NPARTITIONS).compute()\n",
    "\n",
    "df_yahoo.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17616897 entries, 0 to 17616896\n",
      "Columns: 153 entries, date to bloomberg_ticker\n",
      "dtypes: datetime64[ns](1), float64(150), object(2)\n",
      "memory usage: 20.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_yahoo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the yahoo tickers to bloomberg tickers in the ddf_yahoo\n",
    "Set to True if downloading data. The mapping should already be saved in the dumped parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_BLOOMBERG_TICKER_FROM_YAHOO = False\n",
    "if CREATE_BLOOMBERG_TICKER_FROM_YAHOO:\n",
    "    df_yahoo.loc[:, 'bloomberg_ticker'] = df_yahoo['yahoo_ticker'].map(dict(zip(ticker_map['yahoo'], ticker_map['bloomberg_ticker'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save df_yahoo to a feather or parquet file for faster loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 23 µs, total: 36 µs\n",
      "Wall time: 42.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SAVE_DF_YAHOO_TO_FEATHER = False\n",
    "SAVE_DF_YAHOO_TO_PARQUET = False\n",
    "\n",
    "DF_YAHOO_OUTPATH = 'data/yfinance/df_yahoo_' + str(datetime.datetime.today().date())\n",
    "if SAVE_DF_YAHOO_TO_FEATHER:\n",
    "    df_yahoo.reset_index().to_feather(DF_YAHOO_OUTPATH + '.feather')\n",
    "if SAVE_DF_YAHOO_TO_PARQUET:\n",
    "    df_yahoo.to_parquet(DF_YAHOO_OUTPATH + '.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the numerai targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 602 ms, total: 1.91 s\n",
      "Wall time: 16.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "      <th>friday_date</th>\n",
       "      <th>data_type</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4299721</th>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299722</th>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-03-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bloomberg_ticker  friday_date   data_type  target       date\n",
       "4299721          ZYXI US     20210326  validation     0.5 2021-03-26\n",
       "4299722           ZZZ CN     20210326  validation     0.5 2021-03-26"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# targets_address = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val.csv' # old\n",
    "targets_address = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val_bbg.csv'\n",
    "\n",
    "targets = pd.read_csv(targets_address)\\\n",
    "            .assign(date = lambda df: pd.to_datetime(df['friday_date'], format='%Y%m%d'))\n",
    "targets.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.50    2151203\n",
       " 0.25     859478\n",
       " 0.75     859032\n",
       " 1.00     215071\n",
       " 0.00     214939\n",
       " Name: target, dtype: int64,\n",
       " 0.50    0.500312\n",
       " 0.25    0.199891\n",
       " 0.75    0.199788\n",
       " 1.00    0.050020\n",
       " 0.00    0.049989\n",
       " Name: target, dtype: float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['target'].value_counts(), targets['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17616897, 153)\n",
      "(0, 153)\n",
      "(17616897, 3)\n",
      "(17551417, 6)\n",
      "CPU times: user 10.2 s, sys: 2.06 s, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(df_yahoo.shape)\n",
    "print(df_yahoo.dropna().shape)\n",
    "print(df_yahoo.dropna(axis=1).shape)\n",
    "print(df_yahoo[[i for i in df_yahoo.columns if i.endswith('d')]].dropna().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First iteration (reduced dataset size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge targets into ddf_yahoo\n",
    "- From an inner join on `['date', 'bloomberg_ticker']` we lose about 85% of rows. <br>\n",
    "- If we drop rows with NAs we have 0 rows left no matter what. <br>\n",
    "- The best bet seems to be an outer join without dropping NA rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Join\n",
    "- By doing an inner join we lose about 85% of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.14 s, sys: 1.03 s, total: 6.17 s\n",
      "Wall time: 6.18 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_1h_18</th>\n",
       "      <th>volume_1h_19</th>\n",
       "      <th>volume_1h_20</th>\n",
       "      <th>volume_1h_21</th>\n",
       "      <th>volume_1h_22</th>\n",
       "      <th>volume_1h_23</th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "      <th>friday_date</th>\n",
       "      <th>data_type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2633674</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZURN.SW</td>\n",
       "      <td>402.100006</td>\n",
       "      <td>402.100006</td>\n",
       "      <td>404.700012</td>\n",
       "      <td>400.899994</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>512509.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZURN SW</td>\n",
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633675</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>456200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65519.0</td>\n",
       "      <td>63185.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633676</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>14.880000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>456200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>65519.0</td>\n",
       "      <td>63185.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZYXI US</td>\n",
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633677</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5822.0</td>\n",
       "      <td>5578.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633678</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5822.0</td>\n",
       "      <td>5578.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZZZ CN</td>\n",
       "      <td>20210326</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date yahoo_ticker  adj_close_1d    close_1d     high_1d  \\\n",
       "2633674 2021-03-26      ZURN.SW    402.100006  402.100006  404.700012   \n",
       "2633675 2021-03-26         ZYXI     14.880000   14.880000   15.500000   \n",
       "2633676 2021-03-26         ZYXI     14.880000   14.880000   15.500000   \n",
       "2633677 2021-03-26       ZZZ.TO     32.060001   32.060001   32.060001   \n",
       "2633678 2021-03-26       ZZZ.TO     32.060001   32.060001   32.060001   \n",
       "\n",
       "             low_1d     open_1d  volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "2633674  400.899994  401.000000   512509.0             NaN             NaN   \n",
       "2633675   14.400000   15.500000   456200.0             NaN             NaN   \n",
       "2633676   14.400000   15.500000   456200.0             NaN             NaN   \n",
       "2633677   31.625000   31.709999    40900.0             NaN             NaN   \n",
       "2633678   31.625000   31.709999    40900.0             NaN             NaN   \n",
       "\n",
       "         ...  volume_1h_18  volume_1h_19  volume_1h_20  volume_1h_21  \\\n",
       "2633674  ...           NaN           NaN           NaN           NaN   \n",
       "2633675  ...       65519.0       63185.0           NaN           NaN   \n",
       "2633676  ...       65519.0       63185.0           NaN           NaN   \n",
       "2633677  ...        5822.0        5578.0           NaN           NaN   \n",
       "2633678  ...        5822.0        5578.0           NaN           NaN   \n",
       "\n",
       "         volume_1h_22  volume_1h_23  bloomberg_ticker  friday_date  \\\n",
       "2633674           NaN           NaN           ZURN SW     20210326   \n",
       "2633675           NaN           NaN           ZYXI US     20210326   \n",
       "2633676           NaN           NaN           ZYXI US     20210326   \n",
       "2633677           NaN           NaN            ZZZ CN     20210326   \n",
       "2633678           NaN           NaN            ZZZ CN     20210326   \n",
       "\n",
       "          data_type  target  \n",
       "2633674  validation    0.25  \n",
       "2633675  validation    0.50  \n",
       "2633676  validation    0.50  \n",
       "2633677  validation    0.50  \n",
       "2633678  validation    0.50  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# print('Before: ', df_yahoo.shape[0].compute(), df_yahoo.shape[1])\n",
    "df_yahoo = pd.merge(df_yahoo, targets, on=['date', 'bloomberg_ticker'], how='inner')\n",
    "\n",
    "# print('After: ', df_yahoo.shape[0].compute(), df_yahoo.shape[1])\n",
    "df_yahoo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.11 ms, sys: 0 ns, total: 5.11 ms\n",
      "Wall time: 4.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_yahoo.set_index('date', inplace=True)\n",
    "df_yahoo.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop rows where the daily prices are NA\n",
    "By dropping rows where the daily prices are NA we lose 0% rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_suffix_nas(df, col_suffix='1d', id_cols=['date', 'bloomberg_ticker']):\n",
    "    \n",
    "    df_ids = df[[col for col in df.columns \\\n",
    "                 if col.endswith(col_suffix) \\\n",
    "                 or col in id_cols]\\\n",
    "               ].dropna()[id_cols].isin(df[id_cols])\n",
    "    \n",
    "    df = df[df[id_cols].isin(df_ids[id_cols])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 3 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DROP_1D_NAS = False\n",
    "if DROP_1D_NAS:\n",
    "    df_yahoo = drop_suffix_nas(df_yahoo, col_suffix='1d')\n",
    "\n",
    "DROP_1H_NAS = False\n",
    "if DROP_1H_NAS:\n",
    "    df_yahoo = drop_suffix_nas(df_yahoo, col_suffix='1h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features\n",
    "### Create naive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 ms, sys: 4.7 ms, total: 138 ms\n",
      "Wall time: 138 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1 HK',\n",
       " '000100 KS',\n",
       " '2 HK',\n",
       " '000210 KS',\n",
       " '000240 KS',\n",
       " '000270 KS',\n",
       " '3 HK',\n",
       " '4 HK',\n",
       " '6 HK',\n",
       " '000660 KS']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "TICKERS = df_yahoo['bloomberg_ticker'].unique().tolist()\n",
    "TICKERS[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_naive_features_single_symbol(df,\\\n",
    "                                        symbol='',\\\n",
    "                                        symbol_sep='',\\\n",
    "                                        open_col='open_1d',\\\n",
    "                                        high_col='high_1d',\\\n",
    "                                        low_col='low_1d',\\\n",
    "                                        close_col='adj_close_1d',\\\n",
    "                                        volume_col='volume_1d',\\\n",
    "                                        new_col_suffix='_1d',\\\n",
    "                                        copy=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    __________ \n",
    "    \n",
    "    df: Pandas-like / dask dataframe\n",
    "        For the stacked yfinance data used for numerai, the syntax is <groupby('bloomberg_ticker').apply(func)>\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if copy: df = df.copy()\n",
    "\n",
    "    df['move' + new_col_suffix] = df[close_col] - df[open_col]\n",
    "    df['move_pct' + new_col_suffix] = df['move' + new_col_suffix] / df[open_col]\n",
    "    df['move_pct_change' + new_col_suffix] = df['move' + new_col_suffix].pct_change()\n",
    "    df['open_minus_prev_close' + new_col_suffix] = df[open_col] - df[close_col].shift()\n",
    "    df['prev_close_pct_chg' + new_col_suffix] = df['move' + new_col_suffix] / df[close_col].shift()\n",
    "\n",
    "    df['range' + new_col_suffix] = df[high_col] - df[low_col]\n",
    "    df['range_pct_change' + new_col_suffix] = df['range' + new_col_suffix].pct_change()\n",
    "\n",
    "    df['high_move' + new_col_suffix] = df[high_col] - df[open_col]\n",
    "    df['high_move_pct' + new_col_suffix] = df['high_move' + new_col_suffix] / df[open_col]\n",
    "    df['high_move_pct_change' + new_col_suffix] = df['high_move' + new_col_suffix].pct_change()\n",
    "\n",
    "    df['low_move' + new_col_suffix] = df[low_col] - df[open_col]\n",
    "    df['low_move_pct' + new_col_suffix] = df['low_move' + new_col_suffix] / df[open_col]\n",
    "    df['low_move_pct_change' + new_col_suffix] = df['low_move' + new_col_suffix].pct_change()\n",
    "\n",
    "    df['volume_diff' + new_col_suffix] = df[volume_col] - df[volume_col].shift()\n",
    "    df['volume_pct_change' + new_col_suffix] = df[volume_col].pct_change()\n",
    "\n",
    "    df['close_minus_low' + new_col_suffix] = df[close_col] - df[low_col]\n",
    "    df['high_minus_close' + new_col_suffix] = df[high_col] - df[close_col]\n",
    "\n",
    "    df['prev_close_minus_low_minus' + new_col_suffix] = df[close_col].shift() - df[low_col]\n",
    "    df['high_minus_prev_close' + new_col_suffix] = df[high_col] - df[close_col].shift()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 2.85 s, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
       "      <th>adj_close_1h_2</th>\n",
       "      <th>...</th>\n",
       "      <th>high_move_pct_change_1d</th>\n",
       "      <th>low_move_1d</th>\n",
       "      <th>low_move_pct_1d</th>\n",
       "      <th>low_move_pct_change_1d</th>\n",
       "      <th>volume_diff_1d</th>\n",
       "      <th>volume_pct_change_1d</th>\n",
       "      <th>close_minus_low_1d</th>\n",
       "      <th>high_minus_close_1d</th>\n",
       "      <th>prev_close_minus_low_minus_1d</th>\n",
       "      <th>high_minus_prev_close_1d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.820000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-0.019287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.673917</td>\n",
       "      <td>-0.390001</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>-0.338981</td>\n",
       "      <td>15100.0</td>\n",
       "      <td>0.122070</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>1.085001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.390001</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430890</td>\n",
       "      <td>-0.084999</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.782054</td>\n",
       "      <td>-97900.0</td>\n",
       "      <td>-0.705331</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.084999</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           yahoo_ticker  adj_close_1d   close_1d    high_1d     low_1d  \\\n",
       "date                                                                     \n",
       "2021-03-12       ZZZ.TO     30.799999  30.799999  30.820000  30.000000   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "\n",
       "              open_1d  volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "date                                                               \n",
       "2021-03-12  30.590000   123700.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "\n",
       "            adj_close_1h_2  ...  high_move_pct_change_1d  low_move_1d  \\\n",
       "date                        ...                                         \n",
       "2021-03-12             NaN  ...                 0.000000    -0.590000   \n",
       "2021-03-19             NaN  ...                 1.673917    -0.390001   \n",
       "2021-03-19             NaN  ...                 0.000000    -0.390001   \n",
       "2021-03-26             NaN  ...                -0.430890    -0.084999   \n",
       "2021-03-26             NaN  ...                 0.000000    -0.084999   \n",
       "\n",
       "            low_move_pct_1d  low_move_pct_change_1d  volume_diff_1d  \\\n",
       "date                                                                  \n",
       "2021-03-12        -0.019287                0.000000             0.0   \n",
       "2021-03-19        -0.012472               -0.338981         15100.0   \n",
       "2021-03-19        -0.012472                0.000000             0.0   \n",
       "2021-03-26        -0.002681               -0.782054        -97900.0   \n",
       "2021-03-26        -0.002681                0.000000             0.0   \n",
       "\n",
       "            volume_pct_change_1d  close_minus_low_1d  high_minus_close_1d  \\\n",
       "date                                                                        \n",
       "2021-03-12              0.000000            0.799999             0.020000   \n",
       "2021-03-19              0.122070            0.850000             0.155001   \n",
       "2021-03-19              0.000000            0.850000             0.155001   \n",
       "2021-03-26             -0.705331            0.435001             0.000000   \n",
       "2021-03-26              0.000000            0.435001             0.000000   \n",
       "\n",
       "            prev_close_minus_low_minus_1d  high_minus_prev_close_1d  \n",
       "date                                                                 \n",
       "2021-03-12                       0.799999                  0.020000  \n",
       "2021-03-19                      -0.080000                  1.085001  \n",
       "2021-03-19                       0.850000                  0.155001  \n",
       "2021-03-26                       0.105000                  0.330002  \n",
       "2021-03-26                       0.435001                  0.000000  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_yahoo = df_yahoo.groupby('bloomberg_ticker', group_keys=False).apply(create_naive_features_single_symbol)\n",
    "df_yahoo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create my own rule based targets as a feature\n",
    "These are things that I would be looking for before I make a trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateTargets():\n",
    "\n",
    "    def __init__(self, df, copy = True):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        __________\n",
    "\n",
    "        df : pandas df\n",
    "        copy : Boolean whether to make a copy of the df before applying transformations\n",
    "        \n",
    "        Note: to compute the target based on pct, pass the pct column names into the individual functions\n",
    "        \"\"\"\n",
    "\n",
    "        self.df = df\n",
    "        self.copy = copy\n",
    "\n",
    "        if self.copy: self.df = self.df.copy()\n",
    "\n",
    "    def create_targets_HL5(self,\\\n",
    "                           strong_buy,\\\n",
    "                           med_buy,\\\n",
    "                           med_sell,\\\n",
    "                           strong_sell,\\\n",
    "                           threshold,\\\n",
    "                           stop,\\\n",
    "                           move_col = 'move_pct',\\\n",
    "                           lm_col = 'low_move_pct',\\\n",
    "                           hm_col = 'high_move_pct',\\\n",
    "                           target_suffix = 'target_HL5'):\n",
    "\n",
    "\n",
    "        # hm stands for high move, lm stands for low move\n",
    "        # Strong Buy\n",
    "        self.df.loc[(self.df[hm_col] >= strong_buy) &\\\n",
    "                            (self.df[lm_col] >= (-1)*stop),\\\n",
    "                            target_suffix] = 4\n",
    "\n",
    "        # Strong Sell\n",
    "        self.df.loc[(self.df[lm_col] <= (-1)*strong_sell) &\\\n",
    "                    (self.df[hm_col] <= stop) &\\\n",
    "                    (self.df[target_suffix] != 4),\\\n",
    "                    target_suffix] = 0\n",
    "\n",
    "        # Medium Buy\n",
    "        self.df.loc[(self.df[hm_col] >= med_buy) &\\\n",
    "                            (self.df[lm_col] >= (-1)*stop) &\\\n",
    "                            (self.df[target_suffix] != 4) &\\\n",
    "                            (self.df[target_suffix] != 0),\\\n",
    "                            target_suffix] = 3\n",
    "\n",
    "        # Medium Sell\n",
    "        self.df.loc[(self.df[lm_col] <= (-1)*med_sell) &\\\n",
    "                            (self.df[hm_col] <= stop) &\\\n",
    "                            (self.df[target_suffix] != 4) &\\\n",
    "                            (self.df[target_suffix] != 0) &\\\n",
    "                            (self.df[target_suffix] != 3),\\\n",
    "                            target_suffix] = 1\n",
    "\n",
    "        # No Trade\n",
    "        self.df.loc[(self.df[target_suffix] != 0) &\\\n",
    "                            (self.df[target_suffix] != 1) &\\\n",
    "                            (self.df[target_suffix] != 3) &\\\n",
    "                            (self.df[target_suffix] != 4),\\\n",
    "                            target_suffix] = 2\n",
    "\n",
    "\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def create_targets_HL3(self,\\\n",
    "                           buy,\\\n",
    "                           sell,\\\n",
    "                           threshold,\\\n",
    "                           stop,\\\n",
    "                           move_col = 'move_pct',\\\n",
    "                           lm_col = 'low_move_pct',\\\n",
    "                           hm_col = 'high_move_pct',\\\n",
    "                           target_suffix = 'target_HL3'):\n",
    "\n",
    "\n",
    "        # hm stands for high move, lm stands for low move\n",
    "        # Buy\n",
    "        self.df.loc[(self.df[hm_col] >= buy) &\\\n",
    "                            (self.df[lm_col] >= (-1)*stop),\\\n",
    "                            target_suffix] = 2\n",
    "\n",
    "        # Sell\n",
    "        self.df.loc[(self.df[lm_col] <= (-1)*sell) &\\\n",
    "                            (self.df[hm_col] <= stop) &\\\n",
    "                            (self.df[target_suffix] != 2),\\\n",
    "                            target_suffix] = 0\n",
    "\n",
    "        # No Trade\n",
    "        self.df.loc[(self.df[target_suffix] != 0) &\\\n",
    "                            (self.df[target_suffix] != 2),\\\n",
    "                            target_suffix] = 1\n",
    "\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 378 ms, sys: 288 ms, total: 666 ms\n",
      "Wall time: 666 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_yahoo = CreateTargets(df_yahoo).create_targets_HL3(buy=0.03,\\\n",
    "                                                      sell=0.03,\\\n",
    "                                                      threshold=0.25,\\\n",
    "                                                      stop=.01,\\\n",
    "                                                      move_col = 'move_pct_1d',\\\n",
    "                                                      lm_col = 'low_move_pct_1d',\\\n",
    "                                                      hm_col = 'high_move_pct_1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2224340\n",
       "0.0     213419\n",
       "2.0     195920\n",
       "Name: target_HL3, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0    0.844575\n",
       "0.0    0.081035\n",
       "2.0    0.074390\n",
       "Name: target_HL3, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_yahoo['target_HL3'].value_counts()), display(df_yahoo['target_HL3'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 460 ms, sys: 285 ms, total: 745 ms\n",
      "Wall time: 746 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
       "      <th>adj_close_1h_2</th>\n",
       "      <th>...</th>\n",
       "      <th>low_move_pct_1d</th>\n",
       "      <th>low_move_pct_change_1d</th>\n",
       "      <th>volume_diff_1d</th>\n",
       "      <th>volume_pct_change_1d</th>\n",
       "      <th>close_minus_low_1d</th>\n",
       "      <th>high_minus_close_1d</th>\n",
       "      <th>prev_close_minus_low_minus_1d</th>\n",
       "      <th>high_minus_prev_close_1d</th>\n",
       "      <th>target_HL3</th>\n",
       "      <th>target_HL5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.820000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>-0.338981</td>\n",
       "      <td>15100.0</td>\n",
       "      <td>0.122070</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>1.085001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.782054</td>\n",
       "      <td>-97900.0</td>\n",
       "      <td>-0.705331</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.330002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           yahoo_ticker  adj_close_1d   close_1d    high_1d     low_1d  \\\n",
       "date                                                                     \n",
       "2021-03-12       ZZZ.TO     30.799999  30.799999  30.820000  30.000000   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "\n",
       "              open_1d  volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "date                                                               \n",
       "2021-03-12  30.590000   123700.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "\n",
       "            adj_close_1h_2  ...  low_move_pct_1d  low_move_pct_change_1d  \\\n",
       "date                        ...                                            \n",
       "2021-03-12             NaN  ...        -0.019287                0.000000   \n",
       "2021-03-19             NaN  ...        -0.012472               -0.338981   \n",
       "2021-03-19             NaN  ...        -0.012472                0.000000   \n",
       "2021-03-26             NaN  ...        -0.002681               -0.782054   \n",
       "2021-03-26             NaN  ...        -0.002681                0.000000   \n",
       "\n",
       "            volume_diff_1d  volume_pct_change_1d  close_minus_low_1d  \\\n",
       "date                                                                   \n",
       "2021-03-12             0.0              0.000000            0.799999   \n",
       "2021-03-19         15100.0              0.122070            0.850000   \n",
       "2021-03-19             0.0              0.000000            0.850000   \n",
       "2021-03-26        -97900.0             -0.705331            0.435001   \n",
       "2021-03-26             0.0              0.000000            0.435001   \n",
       "\n",
       "            high_minus_close_1d  prev_close_minus_low_minus_1d  \\\n",
       "date                                                             \n",
       "2021-03-12             0.020000                       0.799999   \n",
       "2021-03-19             0.155001                      -0.080000   \n",
       "2021-03-19             0.155001                       0.850000   \n",
       "2021-03-26             0.000000                       0.105000   \n",
       "2021-03-26             0.000000                       0.435001   \n",
       "\n",
       "            high_minus_prev_close_1d  target_HL3  target_HL5  \n",
       "date                                                          \n",
       "2021-03-12                  0.020000         1.0         1.0  \n",
       "2021-03-19                  1.085001         1.0         3.0  \n",
       "2021-03-19                  0.155001         1.0         3.0  \n",
       "2021-03-26                  0.330002         1.0         2.0  \n",
       "2021-03-26                  0.000000         1.0         2.0  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_yahoo = CreateTargets(df_yahoo).create_targets_HL5(strong_buy=0.035,\\\n",
    "                                                      med_buy=0.015,\\\n",
    "                                                      med_sell=0.015,\\\n",
    "                                                      strong_sell=0.035,\\\n",
    "                                                      threshold=0.25,\\\n",
    "                                                      stop=.025,\\\n",
    "                                                      move_col = 'move_pct_1d',\\\n",
    "                                                      lm_col = 'low_move_pct_1d',\\\n",
    "                                                      hm_col = 'high_move_pct_1d')\n",
    "df_yahoo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1069661\n",
       "3.0     585406\n",
       "1.0     585000\n",
       "0.0     201187\n",
       "4.0     192425\n",
       "Name: target_HL5, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2.0    0.406147\n",
       "3.0    0.222277\n",
       "1.0    0.222123\n",
       "0.0    0.076390\n",
       "4.0    0.073063\n",
       "Name: target_HL5, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_yahoo['target_HL5'].value_counts()), display(df_yahoo['target_HL5'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some more features before applying preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagging_features(df, lagging_map, groupby_cols=None, new_col_prefix='prev', copy=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    \n",
    "    df : pandas df\n",
    "    groupby_cols : str or list of cols to groupby before creating lagging transformation cols\n",
    "    lagging_map : dict with keys as colnames and values as a list of periods for computing lagging features\n",
    "    periods : periods to look back\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if copy: df = df.copy()\n",
    "\n",
    "    unique_lagging_values = list(sorted({k for v in lagging_map.values() for k in v}))\n",
    "    \n",
    "    if groupby_cols is None or len(groupby_cols) == 0:\n",
    "        for period in unique_lagging_values:\n",
    "            new_col_prefix_tmp = new_col_prefix + str(period) + '_'\n",
    "            cols_to_lag = [k for k,v in lagging_map.items() if period in v]\n",
    "            df[[new_col_prefix_tmp + c for c in cols_to_lag]] = df[cols_to_lag].transform(lambda s: s.shift(periods=period))\n",
    "    \n",
    "    else:\n",
    "        for period in unique_lagging_values:\n",
    "            new_col_prefix_tmp = new_col_prefix + str(period) + '_'\n",
    "            cols_to_lag = [k for k,v in lagging_map.items() if period in v]\n",
    "            \n",
    "            df[[new_col_prefix_tmp + c for c in cols_to_lag]] = df.groupby(groupby_cols)[cols_to_lag]\\\n",
    "                                                                  .transform(lambda s: s.shift(periods=period))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': [1, 2, 3, 4, 5],\n",
       " 'target_HL5': [1, 2, 3, 4, 5],\n",
       " 'volume_1d': [1, 2, 3, 4, 5],\n",
       " 'adj_close_1d': [1, 2, 3, 4, 5],\n",
       " 'move_1d': [1, 2, 3, 4, 5]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAGGING_MAP = {'target': [1, 2, 3, 4, 5],\\\n",
    "               'target_HL5': [1, 2, 3, 4, 5],\\\n",
    "               'volume_1d': [1, 2, 3, 4, 5],\\\n",
    "               'adj_close_1d' : [1, 2, 3, 4, 5],\\\n",
    "               'move_1d':[1,2,3,4,5]}\n",
    "LAGGING_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.9 s, sys: 4.17 s, total: 46.1 s\n",
      "Wall time: 46.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yahoo_ticker</th>\n",
       "      <th>adj_close_1d</th>\n",
       "      <th>close_1d</th>\n",
       "      <th>high_1d</th>\n",
       "      <th>low_1d</th>\n",
       "      <th>open_1d</th>\n",
       "      <th>volume_1d</th>\n",
       "      <th>adj_close_1h_0</th>\n",
       "      <th>adj_close_1h_1</th>\n",
       "      <th>adj_close_1h_2</th>\n",
       "      <th>...</th>\n",
       "      <th>prev4_target</th>\n",
       "      <th>prev4_target_HL5</th>\n",
       "      <th>prev4_volume_1d</th>\n",
       "      <th>prev4_adj_close_1d</th>\n",
       "      <th>prev4_move_1d</th>\n",
       "      <th>prev5_target</th>\n",
       "      <th>prev5_target_HL5</th>\n",
       "      <th>prev5_volume_1d</th>\n",
       "      <th>prev5_adj_close_1d</th>\n",
       "      <th>prev5_move_1d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.820000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106100.0</td>\n",
       "      <td>26.930000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106100.0</td>\n",
       "      <td>26.930000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>30.549999</td>\n",
       "      <td>-0.380001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106100.0</td>\n",
       "      <td>26.930000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-19</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>31.885000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>138800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>30.549999</td>\n",
       "      <td>-0.380001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>30.549999</td>\n",
       "      <td>-0.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>0.209999</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>30.549999</td>\n",
       "      <td>-0.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>ZZZ.TO</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>0.209999</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123700.0</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>0.209999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           yahoo_ticker  adj_close_1d   close_1d    high_1d     low_1d  \\\n",
       "date                                                                     \n",
       "2021-03-12       ZZZ.TO     30.799999  30.799999  30.820000  30.000000   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-19       ZZZ.TO     31.730000  31.730000  31.885000  30.879999   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "2021-03-26       ZZZ.TO     32.060001  32.060001  32.060001  31.625000   \n",
       "\n",
       "              open_1d  volume_1d  adj_close_1h_0  adj_close_1h_1  \\\n",
       "date                                                               \n",
       "2021-03-12  30.590000   123700.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-19  31.270000   138800.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "2021-03-26  31.709999    40900.0             NaN             NaN   \n",
       "\n",
       "            adj_close_1h_2  ...  prev4_target  prev4_target_HL5  \\\n",
       "date                        ...                                   \n",
       "2021-03-12             NaN  ...          0.75               3.0   \n",
       "2021-03-19             NaN  ...          0.50               1.0   \n",
       "2021-03-19             NaN  ...          0.50               1.0   \n",
       "2021-03-26             NaN  ...          0.75               1.0   \n",
       "2021-03-26             NaN  ...          0.75               1.0   \n",
       "\n",
       "            prev4_volume_1d  prev4_adj_close_1d  prev4_move_1d  prev5_target  \\\n",
       "date                                                                           \n",
       "2021-03-12         106100.0           26.930000       0.600000          0.75   \n",
       "2021-03-19         340600.0           30.549999      -0.380001          0.75   \n",
       "2021-03-19         340600.0           30.549999      -0.380001          0.50   \n",
       "2021-03-26         123700.0           30.799999       0.209999          0.50   \n",
       "2021-03-26         123700.0           30.799999       0.209999          0.75   \n",
       "\n",
       "            prev5_target_HL5  prev5_volume_1d  prev5_adj_close_1d  \\\n",
       "date                                                                \n",
       "2021-03-12               3.0         106100.0           26.930000   \n",
       "2021-03-19               3.0         106100.0           26.930000   \n",
       "2021-03-19               1.0         340600.0           30.549999   \n",
       "2021-03-26               1.0         340600.0           30.549999   \n",
       "2021-03-26               1.0         123700.0           30.799999   \n",
       "\n",
       "            prev5_move_1d  \n",
       "date                       \n",
       "2021-03-12       0.600000  \n",
       "2021-03-19       0.600000  \n",
       "2021-03-19      -0.380001  \n",
       "2021-03-26      -0.380001  \n",
       "2021-03-26       0.209999  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_yahoo = create_lagging_features(df_yahoo, groupby_cols='bloomberg_ticker', lagging_map=LAGGING_MAP)\n",
    "df_yahoo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create rolling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolling_features(df,\\\n",
    "                            rolling_fn,\\\n",
    "                            rolling_params,\\\n",
    "                            ewm_fn,\\\n",
    "                            ewm_params,\\\n",
    "                            rolling_cols = 'all_numeric',\\\n",
    "                            ewm_cols='all_numeric',\\\n",
    "                            join_method='outer',\\\n",
    "                            groupby_cols=None,\\\n",
    "                            create_diff_cols=True,\n",
    "                            copy=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : pandas df\n",
    "    \n",
    "    rolling_fn : str called from df.rolling().rolling_fn (e.g. df.rolling.mean() is called with getattr)\n",
    "    rolling_params : dict params passed to df.rolling()\n",
    "    \n",
    "    ewm_fn : str called from df.ewm().ewm_fn (e.g. df.ewm.mean() is called with getattr)\n",
    "    ewm_params : dict params passed to df.ewm()\n",
    "    \n",
    "    rolling_cols : cols to apply rolling_fn\n",
    "    ewm_cols : cols to apply ewm_fn\n",
    "    \n",
    "    join_method : str 'inner', 'outer', 'left', or 'right' - how to join the dfs\n",
    "    groupby_cols : list or str cols to group by before applying rolling transformations\n",
    "        example: pass groupby_cols to the stacked ticker numerai dataset, but not a wide df \n",
    "    \n",
    "    copy : bool whether or not to make a copy of the df\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if copy: df = df.copy()\n",
    "    \n",
    "    if isinstance(rolling_cols, str) and rolling_cols.lower() == 'all_numeric':\n",
    "        rolling_cols = list(df.select_dtypes(include=np.number).columns)\n",
    "    \n",
    "    if isinstance(rolling_cols, str) and ewm_cols.lower() == 'all_numeric':\n",
    "        ewm_cols = list(df.select_dtypes(include=np.number).columns)\n",
    "    \n",
    "    lag_dfs_lst = []\n",
    "    \n",
    "    if groupby_cols is None or len(groupby_cols) == 0:\n",
    "        \n",
    "        # rolling\n",
    "        lag_dfs_lst.append(getattr(df[rolling_cols].rolling(**rolling_params), rolling_fn)().add_suffix('_rolling_' + rolling_fn))\n",
    "        \n",
    "        # ewm\n",
    "        lag_dfs_lst.append(getattr(df[ewm_cols].ewm(**ewm_params), ewm_fn)().add_suffix('_ewm_' + ewm_fn))\n",
    "    else:\n",
    "        \n",
    "        if isinstance(groupby_cols, list):\n",
    "            assert(len(groupby_cols) == len(set(groupby_cols))), 'There are duplicates in groupby_cols!'\n",
    "            rolling_cols_to_select = [i for i in list(set(groupby_cols + rolling_cols)) if i in df.columns] # could be index name\n",
    "            ewm_cols_to_select = [i for i in list(set(groupby_cols + ewm_cols)) if i in df.columns] # could be index name\n",
    "        elif isinstance(groupby_cols, str):\n",
    "            rolling_cols_to_select = [i for i in list(set([groupby_cols] + rolling_cols)) if i in df.columns]\n",
    "            ewm_cols_to_select = [i for i in list(set([groupby_cols] + ewm_cols)) if i in df.columns]\n",
    "        else:\n",
    "            raise('Input param groupby_cols is not a list, string, or None!')\n",
    "        \n",
    "        # rolling\n",
    "        lag_dfs_lst.append(\n",
    "            df[rolling_cols_to_select].\\\n",
    "            groupby(groupby_cols).\\\n",
    "            apply(lambda x: getattr(x.rolling(**rolling_params), rolling_fn)()).\\\n",
    "            add_suffix('_rolling_' + rolling_fn)\\\n",
    "        )\n",
    "        \n",
    "        # ewm\n",
    "        lag_dfs_lst.append(\n",
    "            df[ewm_cols_to_select].\\\n",
    "            groupby(groupby_cols).\\\n",
    "            apply(lambda x: getattr(x.ewm(**ewm_params), ewm_fn)()).\\\n",
    "            add_suffix('_ewm_' + ewm_fn)\\\n",
    "        )\n",
    "\n",
    "    df_lag = reduce(lambda x, y: pd.merge(x, y, how=join_method, left_index=True, right_index=True), lag_dfs_lst)    \n",
    "    del lag_dfs_lst\n",
    "    df = pd.merge(df, df_lag, how=join_method, left_index=True, right_index=True)\n",
    "    \n",
    "    del df_lag\n",
    "    \n",
    "    if create_diff_cols:\n",
    "        if groupby_cols is None or len(groupby_cols) == 0:\n",
    "            df = pd.concat([df, df[[i for i in df.columns if 'ewm' in i or 'rolling' in i]].diff().add_suffix('_diff')], axis=1)\n",
    "        else:\n",
    "            diff_cols = [i for i in df.columns if 'ewm' in i or 'rolling' in i]\n",
    "            df[[i + '_diff' for i in diff_cols]] = df.groupby(groupby_cols)[diff_cols].transform(lambda col: col.diff())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Below will use over 130gb of ram if running through jupyter notebook. This notebook will be converted to a py script, which is less memory greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_yahoo = create_rolling_features(df_yahoo,\\\n",
    "                                   rolling_params={'window':30},\\\n",
    "                                   rolling_fn='mean',\\\n",
    "                                   ewm_params={'com':.5},\\\n",
    "                                   ewm_fn='mean',\\\n",
    "                                   rolling_cols = ['open_1d', 'high_1d', 'low_1d', 'adj_close_1d', 'volume_1d', 'prev1_target', 'prev1_target_HL5'],\\\n",
    "                                   ewm_cols = ['open_1d', 'high_1d', 'low_1d', 'adj_close_1d', 'volume_1d', 'prev1_target', 'prev1_target_HL5'],\\\n",
    "                                   join_method='outer',\\\n",
    "                                   groupby_cols = 'bloomberg_ticker',\\\n",
    "                                   create_diff_cols=True)\n",
    "df_yahoo.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a good checkpoint to save the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yahoo.reset_index(drop=True).to_feather(OUTPUT_PATH + 'df_numerai_' + str(datetime.datetime.today().date()) + '.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>130</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>127</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>126</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>129</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  price_diff\n",
       "0     127         NaN\n",
       "1     128         1.0\n",
       "2     131         3.0\n",
       "3     132         1.0\n",
       "4     133         1.0\n",
       "5     132        -1.0\n",
       "6     130        -2.0\n",
       "7     130         0.0\n",
       "8     128        -2.0\n",
       "9     127        -1.0\n",
       "10    126        -1.0\n",
       "11    129         3.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'price': [127, 128, 131, 132, 133, 132, 130, 130, 128, 127, 126, 129]})\n",
    "df['price_diff'] = df['price'].diff()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_move_iar(df, iar_cols, iar_suffix='_iar', copy=True):\n",
    "\n",
    "    if copy: df = df.copy()\n",
    "\n",
    "    tmp1 = df[iar_cols].transform(lambda x: x.cumsum().sub(x.cumsum().mask(x >= 0).ffill(), fill_value=0), axis=0).replace(0, np.nan)\n",
    "    tmp2 = df[iar_cols].transform(lambda x: x.cumsum().sub(x.cumsum().mask(x <= 0).ffill(), fill_value=0), axis=0).replace(0, np.nan)\n",
    "    \n",
    "    assert isinstance(iar_cols, str) or isinstance(iar_cols, list), 'iar_cols must be a str or list!'\n",
    "    \n",
    "    if isinstance(iar_cols, str):\n",
    "        df[iar_cols + iar_suffix] = tmp1.fillna(tmp2).ffill()\n",
    "    else:\n",
    "        df[[i + iar_suffix for i in iar_cols]] = tmp1.fillna(tmp2).ffill()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>price_diff_iar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>130</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>127</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>126</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>129</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  price_diff  price_diff_iar\n",
       "0     127         NaN             NaN\n",
       "1     128         1.0             1.0\n",
       "2     131         3.0             4.0\n",
       "3     132         1.0             5.0\n",
       "4     133         1.0             6.0\n",
       "5     132        -1.0            -1.0\n",
       "6     130        -2.0            -3.0\n",
       "7     130         0.0            -3.0\n",
       "8     128        -2.0            -5.0\n",
       "9     127        -1.0            -6.0\n",
       "10    126        -1.0            -7.0\n",
       "11    129         3.0             3.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_move_iar(df, 'price_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-b58200bb8060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalc_move_iar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-45cc33ebb94a>\u001b[0m in \u001b[0;36mcalc_move_iar\u001b[0;34m(df, iar_col, iar_suffix, copy)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtmp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miar_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miar_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "calc_move_iar(df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>price_iar</th>\n",
       "      <th>price_diff_iar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>130</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>127</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>126</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>129</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  price_diff  price_iar  price_diff_iar\n",
       "0     127         NaN      127.0             NaN\n",
       "1     128         1.0      255.0             1.0\n",
       "2     131         3.0      386.0             4.0\n",
       "3     132         1.0      518.0             5.0\n",
       "4     133         1.0      651.0             6.0\n",
       "5     132        -1.0      783.0            -1.0\n",
       "6     130        -2.0      913.0            -3.0\n",
       "7     130         0.0     1043.0            -3.0\n",
       "8     128        -2.0     1171.0            -5.0\n",
       "9     127        -1.0     1298.0            -6.0\n",
       "10    126        -1.0     1424.0            -7.0\n",
       "11    129         3.0     1553.0             3.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_move_iar(df, ['price','price_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8c7502573174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price_iar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price_diff_iar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_move_iar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'price_diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3188\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3189\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3190\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3191\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "df[['price_iar', 'price_diff_iar']] = calc_move_iar(df, ['price','price_diff'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iar_col='price_diff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_diff</th>\n",
       "      <th>move_iar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>130</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>127</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>126</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>129</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  price_diff  move_iar\n",
       "0     127         NaN       NaN\n",
       "1     128         1.0       1.0\n",
       "2     131         3.0       4.0\n",
       "3     132         1.0       5.0\n",
       "4     133         1.0       6.0\n",
       "5     132        -1.0      -1.0\n",
       "6     130        -2.0      -3.0\n",
       "7     130         0.0      -3.0\n",
       "8     128        -2.0      -5.0\n",
       "9     127        -1.0      -6.0\n",
       "10    126        -1.0      -7.0\n",
       "11    129         3.0       3.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = df[iar_col].transform(lambda x: x.cumsum().sub(x.cumsum().mask(x >= 0).ffill(), fill_value=0), axis=0).replace(0, np.nan)\n",
    "tmp2 = df[iar_col].transform(lambda x: x.cumsum().sub(x.cumsum().mask(x <= 0).ffill(), fill_value=0), axis=0).replace(0, np.nan)\n",
    "df['move_iar'] = tmp1.fillna(tmp2).ffill()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "5    -1.0\n",
       "6    -3.0\n",
       "7    -3.0\n",
       "8    -2.0\n",
       "9    -3.0\n",
       "10   -4.0\n",
       "11    3.0\n",
       "Name: price_diff, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[iar_col] = tmp1.fillna(tmp2).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a lot of missing targets. What do we do with them?\n",
    "- This becomes a semi-supervised learning problem since there is likely predictive information where there is no numerai target <br>\n",
    "- To fill them in, I'm going to take an educated guess and say that Numerai's targets are created based on profitable up moves in the market. <br>\n",
    "- The target they created is likely the following multi-class groups: **strong-short**, **short**, **no-trade**, **buy**, **strong-buy** - Let's find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5337, 0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_with_target = df_yahoo.loc[df_yahoo['target'].notnull(), 'bloomberg_ticker'].unique().tolist()\n",
    "tickers_without_target = df_yahoo.loc[df_yahoo['target'].isnull(), 'bloomberg_ticker'].unique().tolist()\n",
    "len(tickers_with_target), len(tickers_without_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOFVjPU0yu7A"
   },
   "outputs": [],
   "source": [
    "ticker_groups = full_data.groupby('ticker')\n",
    "\n",
    "#create lagged features, lag 0 is that day's value, lag 1 is yesterday's value, etc\n",
    "num_days = 5\n",
    "for day in range(num_days+1):\n",
    "    full_data[f'RSI_quintile_lag_{day}'] = ticker_groups['RSI_quintile'].transform(lambda group: group.shift(day))\n",
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Es0O8RKKyu-a"
   },
   "outputs": [],
   "source": [
    "# create difference of the lagged features (change in RSI quintile by day)\n",
    "for day in range(num_days):\n",
    "    full_data[f'RSI_diff_{day}'] = full_data[f'RSI_quintile_lag_{day}'] - full_data[f'RSI_quintile_lag_{day + 1}']\n",
    "    full_data[f'RSI_abs_diff_{day}'] = np.abs(full_data[f'RSI_quintile_lag_{day}'] - full_data[f'RSI_quintile_lag_{day + 1}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkrsTeFuyvBq"
   },
   "outputs": [],
   "source": [
    "feature_names = [f'RSI_quintile_lag_{num}' for num in range(num_days)] + [f'RSI_diff_{num}' for num in range(num_days)] + [f'RSI_abs_diff_{num}' for num in range(num_days)]\n",
    "print(f'Features for training:\\n {feature_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KahFrrERyvE5"
   },
   "outputs": [],
   "source": [
    "TARGET_NAME = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dqoFqMzyvIG"
   },
   "outputs": [],
   "source": [
    "# read in Signals targets\n",
    "numerai_targets = 'https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_train_val.csv'\n",
    "targets = pd.read_csv(numerai_targets)\n",
    "targets['date'] = pd.to_datetime(targets['friday_date'], format='%Y%m%d')\n",
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0XWeLvZyvLr"
   },
   "outputs": [],
   "source": [
    "# the number of tickers per era has generally increased\n",
    "targets.groupby('date').apply(lambda x: len(x)).plot(kind='line', figsize=(10,4), title='Number of tickers per era')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqC4bJX2yvO8"
   },
   "outputs": [],
   "source": [
    "# the target classes are imbalanced, but we can treat this like a regression problem\n",
    "targets.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVF1kpUkyvSe"
   },
   "outputs": [],
   "source": [
    "# the imbalance is consistent across eras with a constant class ratio of: 5%, 20%, 50%, 20%, 5%\n",
    "pivot_target = targets.groupby(['date','target']).apply(lambda x: len(x)).reset_index(1).pivot(columns='target',values=0)\n",
    "pivot_target.iloc[::20].plot(kind='bar', stacked=True, figsize=(9,3), title='Number of tickers in each class per era')\n",
    "\n",
    "stacked_data = pivot_target.apply(lambda x: x/sum(x), axis=1)\n",
    "stacked_data.iloc[::20].plot(kind='bar', stacked=True, figsize=(9,3), title='Proportion of tickers in each class per era')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7nFiUa-yvXy"
   },
   "outputs": [],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL1psmzPyvbs"
   },
   "outputs": [],
   "source": [
    "# merge our feature data with Numerai targets\n",
    "ML_data = pd.merge(full_data.reset_index(), targets, on=['date','ticker']).set_index('date')\n",
    "# print(f'Number of eras in data: {len(ML_data.index.unique())}')\n",
    "\n",
    "# for training and testing we want clean, complete data only\n",
    "ML_data.dropna(inplace=True)\n",
    "ML_data = ML_data[ML_data.index.weekday==4] # ensure we have only fridays\n",
    "ML_data = ML_data[ML_data.index.value_counts() > 200] # drop eras with under 200 observations per era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeymnV_nzT5d"
   },
   "outputs": [],
   "source": [
    "print(f'Number of eras in data: {len(ML_data.index.unique())}')\n",
    "ML_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcLutuwHzT8_"
   },
   "outputs": [],
   "source": [
    "train_data = ML_data[ML_data['data_type'] == 'train']\n",
    "test_data = ML_data[ML_data['data_type'] == 'validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWE4J6ihzUAR"
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.fit(train_data[feature_names], train_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmssRtBKzUDS"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3))\n",
    "plt.bar(feature_names, model.feature_importances_)\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snk6cOZTzUHN"
   },
   "outputs": [],
   "source": [
    "PREDICTION_NAME = 'prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwdod193zUKP"
   },
   "outputs": [],
   "source": [
    "train_data[PREDICTION_NAME] = model.predict(train_data[feature_names])\n",
    "test_data[PREDICTION_NAME] = model.predict(test_data[feature_names])\n",
    "\n",
    "#show prediction distribution, most should around the center\n",
    "test_data[PREDICTION_NAME].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5OK3cJvzUNw"
   },
   "outputs": [],
   "source": [
    "def score(df):\n",
    "    '''Takes df and calculates spearm correlation from pre-defined cols'''\n",
    "    # method=\"first\" breaks ties based on order in array\n",
    "    return np.corrcoef(\n",
    "        df[TARGET_NAME],\n",
    "        df[PREDICTION_NAME].rank(pct=True, method=\"first\")\n",
    "    )[0,1]\n",
    "\n",
    "def run_analytics(era_scores):\n",
    "    print(f\"Mean Correlation: {era_scores.mean():.4f}\")\n",
    "    print(f\"Median Correlation: {era_scores.median():.4f}\")\n",
    "    print(f\"Standard Deviation: {era_scores.std():.4f}\")\n",
    "    print('\\n')\n",
    "    print(f\"Mean Pseudo-Sharpe: {era_scores.mean()/era_scores.std():.4f}\")\n",
    "    print(f\"Median Pseudo-Sharpe: {era_scores.median()/era_scores.std():.4f}\")\n",
    "    print('\\n')\n",
    "    print(f'Hit Rate (% positive eras): {era_scores.apply(lambda x: np.sign(x)).value_counts()[1]/len(era_scores):.2%}')\n",
    "\n",
    "    era_scores.rolling(10).mean().plot(kind='line', title='Rolling Per Era Correlation Mean', figsize=(15,4))\n",
    "    plt.axhline(y=0.0, color=\"r\", linestyle=\"--\"); plt.show()\n",
    "\n",
    "    era_scores.cumsum().plot(title='Cumulative Sum of Era Scores', figsize=(15,4))\n",
    "    plt.axhline(y=0.0, color=\"r\", linestyle=\"--\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_pLA3_PzURS"
   },
   "outputs": [],
   "source": [
    "# spearman scores by era\n",
    "train_era_scores = train_data.groupby(train_data.index).apply(score)\n",
    "test_era_scores = test_data.groupby(test_data.index).apply(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHPMlABQzUUd"
   },
   "outputs": [],
   "source": [
    "#train scores, in-sample and will be significantly overfit\n",
    "run_analytics(train_era_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFsUxckKzUYj"
   },
   "outputs": [],
   "source": [
    "#test scores, out of sample\n",
    "run_analytics(test_era_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t30vuingzUbd"
   },
   "outputs": [],
   "source": [
    "# choose data as of most recent friday\n",
    "last_friday = datetime.now() + relativedelta(weekday=FR(-1))\n",
    "date_string = last_friday.strftime('%Y-%m-%d')\n",
    "\n",
    "live_data = full_data.loc[date_string].copy()\n",
    "live_data.dropna(subset=feature_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEhtlB4DzUfL"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of live tickers to submit: {len(live_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPmPsAGYztjQ"
   },
   "outputs": [],
   "source": [
    "live_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2er-yacztmB"
   },
   "outputs": [],
   "source": [
    "live_data[PREDICTION_NAME] = model.predict(live_data[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISCnCGQDztop"
   },
   "outputs": [],
   "source": [
    "diagnostic_df = pd.concat([test_data, live_data])\n",
    "diagnostic_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5pfv7VTztr9"
   },
   "outputs": [],
   "source": [
    "diagnostic_df['friday_date'] = diagnostic_df.friday_date.fillna(last_friday.strftime('%Y%m%d')).astype(int)\n",
    "diagnostic_df['data_type'] = diagnostic_df.data_type.fillna('live')\n",
    "diagnostic_df[['ticker','friday_date','data_type','prediction']].reset_index(drop=True).to_csv('example_signal_upload.csv', index=False)\n",
    "diagnostic_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGWNHsMDztuq"
   },
   "outputs": [],
   "source": [
    "# format predictions to match Numerai submission format\n",
    "predictions = live_data[['ticker', PREDICTION_NAME]].copy()\n",
    "\n",
    "# choose account\n",
    "ACCOUNT_NAME = 'ENTER_ACCOUNT_NAME'\n",
    "\n",
    "# write predictions to csv\n",
    "live_data[['ticker', PREDICTION_NAME]].to_csv(f\"{ACCOUNT_NAME} {datetime.now().strftime('%Y%m%d')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBoZIk_xztxf"
   },
   "outputs": [],
   "source": [
    "def submit_model(account_name):\n",
    "    filename = f\"{account_name} {datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "    model_id = napi.get_models()[f'{account_name}']\n",
    "    submission = napi.upload_predictions(filename, model_id=model_id)\n",
    "    print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7M_Y8bYzt07"
   },
   "outputs": [],
   "source": [
    "submit_model(ACCOUNT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pd23tVq_zt3_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "80DA0_H-zt7V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      df_yahoo:  4.4 GiB\n",
      "                       targets: 623.9 MiB\n",
      "                    ticker_map:  1.0 MiB\n",
      "              eligible_tickers: 338.2 KiB\n",
      "                 valid_tickers: 47.3 KiB\n",
      "                       TICKERS: 42.0 KiB\n",
      "                           _40:  9.1 KiB\n",
      "                           _34:  8.7 KiB\n",
      "                           _30:  7.8 KiB\n",
      "                           _26:  7.7 KiB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ep_UuQiVzt-X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yn45a8_ozuBK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fo8lf2BzuEe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def download_yfinance_data(tickers,\n",
      "                           intervals_to_download=['1d', '1h'],\n",
      "                           num_workers=1,\n",
      "                           join_method='outer',\n",
      "                           max_intraday_lookback_days=363,\n",
      "                           **yfinance_params):\n",
      "    \"\"\"\n",
      "    Parameters\n",
      "    __________\n",
      "\n",
      "    See yfinance.download docs for a detailed description of yfinance parameters\n",
      "\n",
      "    tickers : string separated by space tickers to pass to yfinance.download (e.g. \"AAPL MSFT FB\")\n",
      "    intervals_to_download : list of intervals to download OHLCV data for each stock (e.g. ['1w', '1d', '1h'])\n",
      "    num_workers : number of threads used to download the data\n",
      "        so far only 1 thread is implemented\n",
      "    join_method : can be 'inner', 'left', 'right' or 'outer'\n",
      "        if 'outer' then all dates will be present\n",
      "        if 'left' then all dates from the left most table will be present\n",
      "        if 'right' then all dates from the left most table will be present\n",
      "        if 'inner' then all dates must match for each ticker\n",
      "    **yfinance_params : dict - passed to yfinance.dowload(yfinance_params)\n",
      "\n",
      "    NOTE: passing some intervals return unreliable stock data (e.g. '3mo' returns many NA data points when they should not be NA)\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    yfinance_params2 = yfinance_params.copy() # create a copy for min / hour pulls because the start date can only go back 60 days\n",
      "\n",
      "    if num_workers == 1:\n",
      "\n",
      "        list_of_dfs = []\n",
      "\n",
      "        for i in intervals_to_download:\n",
      "\n",
      "            yfinance_params['interval'] = i\n",
      "\n",
      "            if i.endswith('m') or i.endswith('h'): # min or hr\n",
      "\n",
      "                yfinance_params2['interval'] = i\n",
      "                yfinance_params2['start'] = str(datetime.datetime.today().date() - datetime.timedelta(days=max_intraday_lookback_days))\n",
      "\n",
      "\n",
      "                df_i = yfinance.download(tickers, **yfinance_params2).\\\n",
      "                        stack().\\\n",
      "                        add_suffix('_' + str(i)).\\\n",
      "                        reset_index(level=1).\\\n",
      "                        rename(columns={'level_1' : 'ticker'})\n",
      "\n",
      "                df_i = df_i.pivot_table(index=df_i.index.date, columns = ['ticker', df_i.index.hour]).stack(level=1)\n",
      "                df_i.columns = list(pd.Index([str(e[0]).lower() + '_' + str(e[1]).lower() for e in df_i.columns.tolist()]).str.replace(' ', '_'))\n",
      "\n",
      "            else:\n",
      "                df_i = yfinance.download(tickers, **yfinance_params).\\\n",
      "                        stack().\\\n",
      "                        add_suffix('_' + str(i))\n",
      "\n",
      "                df_i.columns = [col.replace(' ', '_').lower() for col in df_i.columns]\n",
      "\n",
      "            df_i.index.names = ['date', 'ticker']\n",
      "\n",
      "            list_of_dfs.append(df_i)\n",
      "\n",
      "\n",
      "        df_yahoo = reduce(lambda x, y: pd.merge(x, y, how=join_method, left_index=True, right_index=True), list_of_dfs)\n",
      "#         df_yahoo.reset_index(level=1, inplace=True)\n",
      "\n",
      "    else:\n",
      "        return 'multi-threading not implemented yet. Set num_workers to 1.'\n",
      "\n",
      "    return df_yahoo\n"
     ]
    }
   ],
   "source": [
    "import inspect as i\n",
    "import sys\n",
    "sys.stdout.write(i.getsource(download_yfinance_data))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "build_numerai_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
